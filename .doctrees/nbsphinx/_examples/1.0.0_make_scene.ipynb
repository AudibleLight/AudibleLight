{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "703f697220473528",
   "metadata": {},
   "source": [
    "# 1.0.0: Make a `Scene`!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc7174a25baaec7",
   "metadata": {},
   "source": [
    "## The `Scene` object\n",
    "\n",
    "The `Scene` object is the primary object we'll be dealing with when working with `AudibleLight`. Our `Scene` object is comparable to `scaper.core.Scaper` or `spatialscaper.core.Scaper`, but with numerous adjustments that make data generation more straightforward and scalable.\n",
    "\n",
    "A basic `Scene` object can be initialised as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95c51e4231f8506f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T14:33:42.589690Z",
     "start_time": "2025-10-30T14:33:36.772673Z"
    }
   },
   "outputs": [],
   "source": [
    "from audiblelight import utils\n",
    "from audiblelight.core import Scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f84f223c405131f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T14:12:19.901207Z",
     "start_time": "2025-10-07T14:12:19.608445Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreateContext: Context created\n"
     ]
    }
   ],
   "source": [
    "scene = Scene(\n",
    "    duration=60,\n",
    "    sample_rate=44100,\n",
    "    backend=\"rlr\",\n",
    "    backend_kwargs=dict(\n",
    "        mesh=utils.get_project_root() / \"tests/test_resources/meshes/Oyens.glb\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9642b3f9da7d3d",
   "metadata": {},
   "source": [
    "`Scene.__init__` takes many optional arguments, which are described in more detail within the documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968ec7aef97b1e0d",
   "metadata": {},
   "source": [
    "## Using distributions\n",
    "\n",
    "When a `Scene` is initialised, various distributions can be passed to allow for randomly sampling parameters such as event start times and durations.\n",
    "\n",
    "These durations must satisfy the following conditions:\n",
    "- Must be callable without arguments\n",
    "- OR define an `rvs` method that is callable without arguments\n",
    "- Must return a floating point value when called\n",
    "\n",
    "This means that (for example), we can use `scipy` distributions, custom functions, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75040003042643c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "def truncated_gaussian():\n",
    "    return np.clip(np.random.normal(5., 1.), 4, 6)\n",
    "\n",
    "\n",
    "# All of these are valid distributions\n",
    "scene = Scene(\n",
    "    duration=60,\n",
    "    sample_rate=44100,\n",
    "    backend=\"rlr\",\n",
    "    backend_kwargs=dict(\n",
    "        mesh=utils.get_project_root() / \"tests/test_resources/meshes/Oyens.glb\"\n",
    "    ),\n",
    "    scene_start_dist=truncated_gaussian,\n",
    "    event_start_dist=lambda: np.random.uniform(0.0, 10.0),\n",
    "    event_velocity_dist=stats.uniform(10, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925e13c72cc218c6",
   "metadata": {},
   "source": [
    "When an `Event` is added with `Scene.add_event`, the following logic is used to decide whether the distributions passed to `Scene.__init__` should be sampled from:\n",
    "\n",
    "- If overrides are passed directly to `add_event`, these will **always** be used\n",
    "- If overrides are not passed but a valid distribution has been, this will be sampled\n",
    "- If neither overrides nor a distribution has been passed, the value will be sampled from a sensible default distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f1949ffb0003e3",
   "metadata": {},
   "source": [
    "## Passing audio directories\n",
    "\n",
    "We can pass `fg_path` to `Scene.__init__`. This allows us to define a directory (or list of directories) containing foreground audio. When we add an event with `Scene.add_event` **without also specifying** `filepath=...`, we'll pull in from this directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "157d52c36529211",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T14:48:34.422803Z",
     "start_time": "2025-10-30T14:48:32.315242Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-30 14:48:32.400\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36maudiblelight.worldstate\u001b[0m:\u001b[36mload_mesh_navigation_waypoints\u001b[0m:\u001b[36m1878\u001b[0m - \u001b[33m\u001b[1mCannot find waypoints for mesh Oyens inside default location (/home/huw-cheston/Documents/python_projects/AudibleLight/resources/waypoints/gibson). No navigation waypoints will be loaded.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreateContext: Context created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: initializing context twice. Will destroy old context and create a new one.\n",
      "\u001b[32m2025-10-30 14:48:34.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36maudiblelight.core\u001b[0m:\u001b[36madd_event\u001b[0m:\u001b[36m961\u001b[0m - \u001b[1mEvent added successfully: Static 'Event' with alias 'will_be_music', audio file '/home/huw-cheston/Documents/python_projects/AudibleLight/tests/test_resources/soundevents/music/001666.mp3' (unloaded, 0 augmentations), 1 emitter(s).\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreateContext: Context created\n",
      "/home/huw-cheston/Documents/python_projects/AudibleLight/tests/test_resources/soundevents/music/001666.mp3\n"
     ]
    }
   ],
   "source": [
    "scene = Scene(\n",
    "    duration=60,\n",
    "    sample_rate=44100,\n",
    "    backend=\"rlr\",\n",
    "    backend_kwargs=dict(\n",
    "        mesh=utils.get_project_root() / \"tests/test_resources/meshes/Oyens.glb\"\n",
    "    ),\n",
    "    fg_path=utils.get_project_root() / \"tests/test_resources/soundevents/music\"\n",
    ")\n",
    "scene.add_event(event_type=\"static\", alias=\"will_be_music\")\n",
    "music_event = scene.get_event(\"will_be_music\")\n",
    "print(music_event.filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8392213dcf7566e5",
   "metadata": {},
   "source": [
    "In this example, we pass in a directory containing music objects. When we add an `Event` to the `Scene`, we'll draw from this dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecb52fd4e25f35d",
   "metadata": {},
   "source": [
    "### Controlling duplicate audio files\n",
    "\n",
    "By default, we allow a single unique audio file to appear numerous times in a `Scene`. In practice, this is usually not a problem as we would expect `fg_dir` to contain many audio files, and therefore duplicates (especially overlapping duplicates) are in reality very rare.\n",
    "\n",
    "If this behaviour is undesirable, the argument `allow_duplicate_audios=False` can be passed when initialising a `Scene`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26d2dac7eb0ff70c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T14:27:58.253495Z",
     "start_time": "2025-10-07T14:27:55.485338Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreateContext: Context created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: initializing context twice. Will destroy old context and create a new one.\n",
      "\u001b[32m2025-10-07 15:27:57.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36maudiblelight.core\u001b[0m:\u001b[36madd_event\u001b[0m:\u001b[36m830\u001b[0m - \u001b[1mEvent added successfully: Static 'Event' with alias 'event000', audio file '/home/huw-cheston/Documents/python_projects/AudibleLight/tests/test_resources/soundevents/music/007527.mp3' (unloaded, 0 augmentations), 1 emitter(s).\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreateContext: Context created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: initializing context twice. Will destroy old context and create a new one.\n",
      "\u001b[32m2025-10-07 15:27:58.251\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36maudiblelight.core\u001b[0m:\u001b[36madd_event\u001b[0m:\u001b[36m830\u001b[0m - \u001b[1mEvent added successfully: Static 'Event' with alias 'event001', audio file '/home/huw-cheston/Documents/python_projects/AudibleLight/tests/test_resources/soundevents/music/001666.mp3' (unloaded, 0 augmentations), 1 emitter(s).\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreateContext: Context created\n",
      "007527.mp3\n",
      "001666.mp3\n"
     ]
    }
   ],
   "source": [
    "no_dupes_allowed = Scene(\n",
    "    duration=60,\n",
    "    sample_rate=44100,\n",
    "    backend=\"rlr\",\n",
    "    backend_kwargs=dict(\n",
    "        mesh=utils.get_project_root() / \"tests/test_resources/meshes/Oyens.glb\"\n",
    "    ),\n",
    "    fg_path=utils.get_project_root() / \"tests/test_resources/soundevents/music\",\n",
    "    allow_duplicate_audios=False\n",
    ")\n",
    "\n",
    "# Add in some music files\n",
    "for _ in range(2):\n",
    "    no_dupes_allowed.add_event(event_type=\"static\")\n",
    "\n",
    "# Print the filepaths\n",
    "events = no_dupes_allowed.get_events()\n",
    "for ev in events:\n",
    "    print(ev.filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ac0ca47b6b78d6",
   "metadata": {},
   "source": [
    "### Serialising `Scene` objects\n",
    "\n",
    "`Scene` objects can be serialised to a Python dictionary or JSON object using the `to_dict` method.\n",
    "\n",
    "This makes it easy to inspect the object and its parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dad22b15089b8f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T14:48:49.124031Z",
     "start_time": "2025-10-30T14:48:49.095972Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'audiblelight_version': '0.1.0',\n",
       " 'rlr_audio_propagation_version': '0.0.1',\n",
       " 'creation_time': '2025-10-30_14:48:49',\n",
       " 'duration': 60.0,\n",
       " 'backend': 'RLR',\n",
       " 'sample_rate': 44100,\n",
       " 'ref_db': -65,\n",
       " 'max_overlap': 2,\n",
       " 'fg_path': ['/home/huw-cheston/Documents/python_projects/AudibleLight/tests/test_resources/soundevents/music'],\n",
       " 'bg_path': [],\n",
       " 'ambience': {},\n",
       " 'events': {'will_be_music': {'alias': 'will_be_music',\n",
       "   'filename': '001666.mp3',\n",
       "   'filepath': '/home/huw-cheston/Documents/python_projects/AudibleLight/tests/test_resources/soundevents/music/001666.mp3',\n",
       "   'class_id': 8,\n",
       "   'class_label': 'music',\n",
       "   'is_moving': False,\n",
       "   'scene_start': 3.6278842385833543,\n",
       "   'scene_end': 33.60446020230218,\n",
       "   'event_start': 0.0,\n",
       "   'event_end': 29.976575963718822,\n",
       "   'duration': 29.976575963718822,\n",
       "   'snr': np.float64(21.866501465167776),\n",
       "   'sample_rate': 44100.0,\n",
       "   'spatial_resolution': None,\n",
       "   'spatial_velocity': None,\n",
       "   'shape': 'static',\n",
       "   'num_emitters': 1,\n",
       "   'emitters': [[3.9456078535606425, -0.2135563826678748, 0.5030086457338951]],\n",
       "   'emitters_relative': {},\n",
       "   'augmentations': []}},\n",
       " 'state': {'backend': 'RLR',\n",
       "  'sample_rate': 44100,\n",
       "  'emitters': {'will_be_music': [[3.9456078535606425,\n",
       "     -0.2135563826678748,\n",
       "     0.5030086457338951]]},\n",
       "  'microphones': {},\n",
       "  'mesh': {'fname': 'Oyens',\n",
       "   'ftype': '.glb',\n",
       "   'fpath': '/home/huw-cheston/Documents/python_projects/AudibleLight/tests/test_resources/meshes/Oyens.glb',\n",
       "   'units': 'meters',\n",
       "   'from_gltf_primitive': False,\n",
       "   'name': 'defaultobject',\n",
       "   'node': 'defaultobject',\n",
       "   'bounds': [[-3.0433080196380615, -10.448445320129395, -1.1850370168685913],\n",
       "    [5.973234176635742, 2.101027011871338, 2.4577369689941406]],\n",
       "   'centroid': [1.527919030159762, -4.550817438070386, 1.162934397641578]},\n",
       "  'rlr_config': {'diffraction': 1,\n",
       "   'direct': 1,\n",
       "   'direct_ray_count': 500,\n",
       "   'direct_sh_order': 3,\n",
       "   'frequency_bands': 4,\n",
       "   'global_volume': 1.0,\n",
       "   'hrtf_back': [0.0, 0.0, 1.0],\n",
       "   'hrtf_right': [1.0, 0.0, 0.0],\n",
       "   'hrtf_up': [0.0, 1.0, 0.0],\n",
       "   'indirect': 1,\n",
       "   'indirect_ray_count': 5000,\n",
       "   'indirect_ray_depth': 200,\n",
       "   'indirect_sh_order': 1,\n",
       "   'max_diffraction_order': 10,\n",
       "   'max_ir_length': 4.0,\n",
       "   'mesh_simplification': 0,\n",
       "   'sample_rate': 44100.0,\n",
       "   'size': 146,\n",
       "   'source_ray_count': 200,\n",
       "   'source_ray_depth': 10,\n",
       "   'temporal_coherence': 0,\n",
       "   'thread_count': 1,\n",
       "   'transmission': 1,\n",
       "   'unit_scale': 1.0},\n",
       "  'empty_space_around_mic': 0.1,\n",
       "  'empty_space_around_emitter': 0.2,\n",
       "  'empty_space_around_surface': 0.2,\n",
       "  'empty_space_around_capsule': 0.05,\n",
       "  'repair_threshold': None,\n",
       "  'material': 'Default'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dict = scene.to_dict()\n",
    "out_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d243a9e67b967179",
   "metadata": {},
   "source": [
    "Serialising to a dictionary of JSON also makes it easy to load the object back up again. To do this, we can instantiate the class using the `from_dict` class method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4f71d2cc10ca3d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T14:48:51.893378Z",
     "start_time": "2025-10-30T14:48:51.368878Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-30 14:48:51.377\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36maudiblelight.core\u001b[0m:\u001b[36mfrom_dict\u001b[0m:\u001b[36m1653\u001b[0m - \u001b[33m\u001b[1mCurrently, distributions cannot be loaded with `Scene.from_dict`. You will need to manually redefine these using, for instance, setattr(scene, 'event_start_dist', ...), repeating this for every distribution.\u001b[0m\n",
      "\u001b[32m2025-10-30 14:48:51.466\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36maudiblelight.worldstate\u001b[0m:\u001b[36mload_mesh_navigation_waypoints\u001b[0m:\u001b[36m1878\u001b[0m - \u001b[33m\u001b[1mCannot find waypoints for mesh Oyens inside default location (/home/huw-cheston/Documents/python_projects/AudibleLight/resources/waypoints/gibson). No navigation waypoints will be loaded.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreateContext: Context created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: initializing context twice. Will destroy old context and create a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreateContext: Context created\n"
     ]
    }
   ],
   "source": [
    "recreated = Scene.from_dict(out_dict)\n",
    "# Alternatively, `Scene.from_json(...)` to load from a JSON object on the disk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954aad29e8b863d",
   "metadata": {},
   "source": [
    "We can use the built in Python `__eq__` method to check that our original and recreated `Scene` are identical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "defe73222684b0e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T14:48:53.237509Z",
     "start_time": "2025-10-30T14:48:53.204658Z"
    }
   },
   "outputs": [],
   "source": [
    "assert scene == recreated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6465e836a1f6f0e5",
   "metadata": {},
   "source": [
    "Nearly every object in `AudibleLight` defines the `to_dict` and `from_dict` method, making it easy to load and unload objects using built-in Python datatypes.\n",
    "\n",
    "Note that loading a higher level object (e.g., `Scene`) will automatically load in any lower level objects (e.g., `Event`, `Augmentation`) too. So, there's no need to call `Event.from_dict` when all you want is `Scene.from_dict`: this will be handled automatically!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81f49d7517909868",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T14:49:00.385896Z",
     "start_time": "2025-10-30T14:49:00.362214Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alias': 'will_be_music',\n",
       " 'filename': '001666.mp3',\n",
       " 'filepath': '/home/huw-cheston/Documents/python_projects/AudibleLight/tests/test_resources/soundevents/music/001666.mp3',\n",
       " 'class_id': 8,\n",
       " 'class_label': 'music',\n",
       " 'is_moving': False,\n",
       " 'scene_start': 3.6278842385833543,\n",
       " 'scene_end': 33.60446020230218,\n",
       " 'event_start': 0.0,\n",
       " 'event_end': 29.976575963718822,\n",
       " 'duration': 29.976575963718822,\n",
       " 'snr': np.float64(21.866501465167776),\n",
       " 'sample_rate': 44100.0,\n",
       " 'spatial_resolution': None,\n",
       " 'spatial_velocity': None,\n",
       " 'shape': 'static',\n",
       " 'num_emitters': 1,\n",
       " 'emitters': [[3.9456078535606425, -0.2135563826678748, 0.5030086457338951]],\n",
       " 'emitters_relative': {},\n",
       " 'augmentations': []}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_as_dict = recreated.get_event(0).to_dict()\n",
    "event_as_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4192603c75a89366",
   "metadata": {},
   "source": [
    "And we can, of course, check that the `Event` objects are equivalent..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b358662b4f9a5126",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T14:49:22.577870Z",
     "start_time": "2025-10-30T14:49:22.572590Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene.get_event(0) == recreated.get_event(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd93072ad5a3f032",
   "metadata": {},
   "source": [
    "### A note on backends\n",
    "\n",
    "`Scene` supports multiple backend types (which inherit from `audiblelight.state.WorldState`):\n",
    "- Ray-traced RIRs, using `rlr-audio-propagation` (`backend=\"rlr\"`)\n",
    "- Measured RIRs, reading from `.sofa` files in a manner similar to `spatialscaper` (`backend=\"sofa\"`)\n",
    "- Parametric (shoebox) RIRs, defined in a similar manner to `pyroomacoustics`\n",
    "\n",
    "The underlying API is the same regardless of backend, however, making it easy to create complex datasets that work with different types of room impulse responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98af0652e900f3a2",
   "metadata": {},
   "source": [
    "The examples given above all use the \"rlr\" backend, but the same principles apply to other backends too.\n",
    "\n",
    "Let's try creating a `Scene` with the \"sofa\" backend. We'll need to pass in a SOFA file, just as we had to pass a mesh file into our RLR backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d4a689a993aaf7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T14:35:23.348880Z",
     "start_time": "2025-10-30T14:35:23.251261Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-30 14:35:23.309\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36maudiblelight.core\u001b[0m:\u001b[36madd_event\u001b[0m:\u001b[36m961\u001b[0m - \u001b[1mEvent added successfully: Static 'Event' with alias 'event000', audio file '/home/huw-cheston/Documents/python_projects/AudibleLight/tests/test_resources/soundevents/music/000010.mp3' (unloaded, 0 augmentations), 1 emitter(s).\u001b[0m\n",
      "\u001b[32m2025-10-30 14:35:23.338\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36maudiblelight.core\u001b[0m:\u001b[36madd_event\u001b[0m:\u001b[36m961\u001b[0m - \u001b[1mEvent added successfully: Static 'Event' with alias 'event001', audio file '/home/huw-cheston/Documents/python_projects/AudibleLight/tests/test_resources/soundevents/music/007527.mp3' (unloaded, 0 augmentations), 1 emitter(s).\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alias': 'event000',\n",
       " 'filename': '000010.mp3',\n",
       " 'filepath': '/home/huw-cheston/Documents/python_projects/AudibleLight/tests/test_resources/soundevents/music/000010.mp3',\n",
       " 'class_id': 8,\n",
       " 'class_label': 'music',\n",
       " 'is_moving': False,\n",
       " 'scene_start': 1.4424073409576228,\n",
       " 'scene_end': 31.418983304676445,\n",
       " 'event_start': 0.0,\n",
       " 'event_end': 29.976575963718822,\n",
       " 'duration': 29.976575963718822,\n",
       " 'snr': np.float64(27.744524358272837),\n",
       " 'sample_rate': 44100.0,\n",
       " 'spatial_resolution': None,\n",
       " 'spatial_velocity': None,\n",
       " 'shape': 'static',\n",
       " 'num_emitters': 1,\n",
       " 'emitters': [[2.4995571849510796,\n",
       "   -0.0004428150489204461,\n",
       "   -0.0004428150489204461]],\n",
       " 'emitters_relative': {'mic000': [[-0.010150371151877405,\n",
       "    -0.010150370992594011,\n",
       "    2.4995572633990406]]},\n",
       " 'augmentations': []}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sofa_scene = Scene(\n",
    "    duration=60,\n",
    "    sample_rate=44100,\n",
    "    backend=\"sofa\",\n",
    "    fg_path=utils.get_project_root() / \"tests/test_resources/soundevents/music\",\n",
    "    allow_duplicate_audios=True,\n",
    "    backend_kwargs=dict(\n",
    "        sofa=utils.get_project_root() / \"tests/test_resources/daga_foa.sofa\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Add in some music files\n",
    "for _ in range(2):\n",
    "    sofa_scene.add_event(event_type=\"static\")\n",
    "\n",
    "# Print the first event\n",
    "sofa_events = sofa_scene.get_event(0)\n",
    "sofa_events.to_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
