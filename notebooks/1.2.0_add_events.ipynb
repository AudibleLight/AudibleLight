{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 1.2.0: Add `Event`s\n",
    "\n",
    "In `AudibleLight`, `Event` objects represent sounds placed within a `Scene`. There are two types of `Event` objects:\n",
    "- Static `Event`s, which occupy the same point in space;\n",
    "- Moving `Event`s, which move through space according to a particular trajectory (e.g., linear, random...)\n",
    "\n",
    "`AudibleLight` defines a comprehensive API for adding `Event` objects to a `Scene`, as well as controlling parameters relating to the underlying audio file (e.g., duration, offset, any augmentations), how it moves through space (e.g., its velocity and resolution), and how it relates to the whole `Scene` (e.g., how loud it is versus the noise floor).\n",
    "\n",
    "Note that the `Augmentation` API for `AudibleLight` has its own tutorial."
   ],
   "id": "703f697220473528"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Adding static `Event` objects",
   "id": "a9c5aa81fe382cea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T15:31:57.731558Z",
     "start_time": "2025-11-04T15:31:51.534305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from audiblelight.core import Scene\n",
    "from audiblelight import utils"
   ],
   "id": "d1bdf6a6927b5d68",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T17:13:18.952013Z",
     "start_time": "2025-11-03T17:13:16.796497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scene = Scene(\n",
    "    duration=60,\n",
    "    sample_rate=44100,\n",
    "    backend=\"rlr\",\n",
    "    backend_kwargs=dict(\n",
    "        mesh=utils.get_project_root() / \"tests/test_resources/meshes/Oyens.glb\"\n",
    "    ),\n",
    "    fg_path=utils.get_project_root() / \"tests/test_resources/soundevents\",\n",
    ")\n",
    "scene.add_microphone(microphone_type=\"ambeovr\")"
   ],
   "id": "ebcbf0ee9858c556",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-11-03 17:13:16.857\u001B[0m | \u001B[33m\u001B[1mWARNING \u001B[0m | \u001B[36maudiblelight.worldstate\u001B[0m:\u001B[36mload_mesh_navigation_waypoints\u001B[0m:\u001B[36m1878\u001B[0m - \u001B[33m\u001B[1mCannot find waypoints for mesh Oyens inside default location (/home/huw-cheston/Documents/python_projects/AudibleLight/resources/waypoints/gibson). No navigation waypoints will be loaded.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreateContext: Context created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: initializing context twice. Will destroy old context and create a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreateContext: Context created\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We are now ready to add an `Event` to our scene. By default, this will start from between 0 and 59 seconds (i.e., `scene.duration` - 1), with an audio file pulled from our `fg_path`.",
   "id": "f3b4133d5b667bfb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T17:13:20.481297Z",
     "start_time": "2025-11-03T17:13:19.066774Z"
    }
   },
   "cell_type": "code",
   "source": "added = scene.add_event(event_type=\"static\", alias=\"my_first_event\")",
   "id": "6c376e1ea155606b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: initializing context twice. Will destroy old context and create a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreateContext: Context created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-11-03 17:13:20.479\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36maudiblelight.core\u001B[0m:\u001B[36madd_event\u001B[0m:\u001B[36m972\u001B[0m - \u001B[1mEvent added successfully: Static 'Event' with alias 'my_first_event', audio file '/home/huw-cheston/Documents/python_projects/AudibleLight/tests/test_resources/soundevents/musicInstrument/8390.wav' (unloaded, 0 augmentations), 1 emitter(s).\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Note that the same functionality could be achieved by calling `Scene.add_event_static` with the same arguments (minus `event_type=\"static\"`).",
   "id": "684ffac4355bd86f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Using overrides\n",
    "\n",
    "To control more parameters of the `Event`, we can pass in arguments to `add_event`. These arguments will **override** any distributions passed to `Scene.__init__`, allowing for more finegrained placing of events."
   ],
   "id": "54a2a6638a8fd92d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T17:13:20.800411Z",
     "start_time": "2025-11-03T17:13:20.533649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "added2 = scene.add_event(\n",
    "    event_type=\"static\",\n",
    "    alias=\"my_second_event\",\n",
    "    filepath=utils.get_project_root() / \"tests/test_resources/soundevents/music/000010.mp3\",\n",
    "    duration=10,\n",
    "    scene_start=5.0,\n",
    "    event_start=2.0,\n",
    "    polar=True,\n",
    "    position=[-45., 0., 0.5]\n",
    ")"
   ],
   "id": "6387f5211e7949a4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: initializing context twice. Will destroy old context and create a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreateContext: Context created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-11-03 17:13:20.798\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36maudiblelight.core\u001B[0m:\u001B[36madd_event\u001B[0m:\u001B[36m972\u001B[0m - \u001B[1mEvent added successfully: Static 'Event' with alias 'my_second_event', audio file '/home/huw-cheston/Documents/python_projects/AudibleLight/tests/test_resources/soundevents/music/000010.mp3' (unloaded, 0 augmentations), 1 emitter(s).\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This example loads in a music file with an offset at 2 seconds and a duration of 10 seconds (i.e., seconds 2 -- 12 will be used). The audio file will start 5 seconds in to the start of the scene. It will be placed 45 degrees to the front-left of the mic, level with the mic, and 0.5 meters away.",
   "id": "fe8ad5b0967eed9d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Note that, when dealing with multiple microphones added to a single `Scene`, as well as passing `polar=True`, we also need to pass the alias of the microphone to `mic=...`, so the correct offset can be calculated.",
   "id": "78f4daf8290685ba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T17:13:22.308745Z",
     "start_time": "2025-11-03T17:13:20.808099Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scene.clear_microphones()\n",
    "mic1 = scene.add_microphone(microphone_type=\"monocapsule\", alias=\"mic_a\")\n",
    "mic2 = scene.add_microphone(microphone_type=\"monocapsule\", alias=\"mic_b\")\n",
    "\n",
    "pol = scene.add_event(\n",
    "    event_type=\"static\",\n",
    "    polar=True,\n",
    "    mic=\"mic_a\",\n",
    "    alias=\"pol\",\n",
    "    position=[-45., 0., 0.5],\n",
    "    duration=1\n",
    ")"
   ],
   "id": "926f0846e5647fd0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: initializing context twice. Will destroy old context and create a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreateContext: Context created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: initializing context twice. Will destroy old context and create a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreateContext: Context created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: initializing context twice. Will destroy old context and create a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreateContext: Context created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: initializing context twice. Will destroy old context and create a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreateContext: Context created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-11-03 17:13:22.305\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36maudiblelight.core\u001B[0m:\u001B[36madd_event\u001B[0m:\u001B[36m972\u001B[0m - \u001B[1mEvent added successfully: Static 'Event' with alias 'pol', audio file '/home/huw-cheston/Documents/python_projects/AudibleLight/tests/test_resources/soundevents/music/007527.mp3' (unloaded, 0 augmentations), 1 emitter(s).\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now, the `pol` `Event` is placed so that it is -45 degrees from the `mic_a` `MicArray`.",
   "id": "761903e476aa5eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "scene.clear_microphone(\"mic_b\")",
   "id": "421086ad93632230"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Controlling duplicate audio files\n",
    "\n",
    "By default, we allow a single unique audio file to appear numerous times in a `Scene`. In practice, this is usually not a problem as we would expect `fg_dir` to contain many audio files, and therefore duplicates (especially overlapping duplicates) are in reality very rare.\n",
    "\n",
    "If this behaviour is undesirable, the argument `allow_duplicate_audios=False` can be passed when initialising a `Scene`:"
   ],
   "id": "4082a2a2746dc90b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "no_dupes_allowed = Scene(\n",
    "    duration=60,\n",
    "    sample_rate=44100,\n",
    "    backend=\"rlr\",\n",
    "    backend_kwargs=dict(\n",
    "        mesh=utils.get_project_root() / \"tests/test_resources/meshes/Oyens.glb\"\n",
    "    ),\n",
    "    fg_path=utils.get_project_root() / \"tests/test_resources/soundevents/music\",\n",
    "    allow_duplicate_audios=False\n",
    ")\n",
    "\n",
    "# Add in some music files\n",
    "for _ in range(2):\n",
    "    no_dupes_allowed.add_event(event_type=\"static\")\n",
    "\n",
    "# Print the filepaths\n",
    "events = no_dupes_allowed.get_events()\n",
    "for ev in events:\n",
    "    print(ev.filename)"
   ],
   "id": "9bd61b586acfd223"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Controlling same class `Event` objects\n",
    "\n",
    "We also allow multiple appearances of the same class by default. For instance, if we have a \"waterTap\" class and `allow_duplicate_audios=False`, we may have multiple instances of \"waterTap\" `Events`, but each will use a different audio file.\n",
    "\n",
    "We can control this behaviour by setting `allow_same_class_events=False` when initialising a `Scene`. This will ensure that every `Event` added to the `Scene` has a unique class:"
   ],
   "id": "de12af47de559070"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T15:39:46.090580Z",
     "start_time": "2025-11-04T15:39:44.262592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "no_same_class_events_allowed = Scene(\n",
    "    duration=60,\n",
    "    sample_rate=44100,\n",
    "    backend=\"rlr\",\n",
    "    backend_kwargs=dict(\n",
    "        mesh=utils.get_project_root() / \"tests/test_resources/meshes/Oyens.glb\"\n",
    "    ),\n",
    "    fg_path=utils.get_project_root() / \"tests/test_resources/soundevents\",\n",
    "    allow_duplicate_audios=False,\n",
    "    allow_same_class_events=False\n",
    ")\n",
    "\n",
    "# Add in a waterTap event\n",
    "tap1 = utils.get_project_root() / \"tests/test_resources/soundevents/waterTap/95709.wav\"\n",
    "no_same_class_events_allowed.add_event(\n",
    "    event_type=\"static\",\n",
    "    filepath=tap1,\n",
    ")\n",
    "\n",
    "# If we try and add another waterTap object, we'll get an error\n",
    "tap2 = utils.get_project_root() / \"tests/test_resources/soundevents/waterTap/205695.wav\"\n",
    "try:\n",
    "    no_same_class_events_allowed.add_event(\n",
    "        event_type=\"static\",\n",
    "        filepath=tap2\n",
    "    )\n",
    "except ValueError as err:\n",
    "    print(f\"Raised error: {err}\")"
   ],
   "id": "9b5e2fc1719959d3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-11-04 15:39:44.303\u001B[0m | \u001B[33m\u001B[1mWARNING \u001B[0m | \u001B[36maudiblelight.worldstate\u001B[0m:\u001B[36mload_mesh_navigation_waypoints\u001B[0m:\u001B[36m1878\u001B[0m - \u001B[33m\u001B[1mCannot find waypoints for mesh Oyens inside default location (/home/huw-cheston/Documents/python_projects/AudibleLight/resources/waypoints/gibson). No navigation waypoints will be loaded.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreateContext: Context created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: initializing context twice. Will destroy old context and create a new one.\n",
      "\u001B[32m2025-11-04 15:39:46.087\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36maudiblelight.core\u001B[0m:\u001B[36madd_event\u001B[0m:\u001B[36m1002\u001B[0m - \u001B[1mEvent added successfully: Static 'Event' with alias 'event000', audio file '/home/huw-cheston/Documents/python_projects/AudibleLight/tests/test_resources/soundevents/waterTap/95709.wav' (unloaded, 0 augmentations), 1 emitter(s).\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreateContext: Context created\n",
      "Raised error: Audio file /home/huw-cheston/Documents/python_projects/AudibleLight/tests/test_resources/soundevents/waterTap/205695.wav uses a class that has already been added to the Scene (10). Either choose a different audio file, or set `Scene.allow_duplicate_audios=False`.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Inspecting `Event` objects",
   "id": "a77cfb016ba0f76f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "For more information on the `Event`, we can use its alias to grab it from the `Scene`",
   "id": "c14518c1c3cd9e8d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T17:13:22.699068Z",
     "start_time": "2025-11-03T17:13:22.695249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "event2 = scene.get_event(\"pol\")\n",
    "print(event2)"
   ],
   "id": "9c88da193845996a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Static 'Event' with alias 'pol', audio file '/home/huw-cheston/Documents/python_projects/AudibleLight/tests/test_resources/soundevents/music/007527.mp3' (unloaded, 0 augmentations), 1 emitter(s).\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We can also load the audio file with `Event.load_audio`.\n",
    "\n",
    "Note that this will happen automatically whenever `scene.generate` is called, so you don't need to worry about making this part of your data generation code."
   ],
   "id": "9f9164f05851413e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T17:13:23.312329Z",
     "start_time": "2025-11-03T17:13:22.743307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "audio = event2.load_audio(ignore_cache=True, normalize=True)\n",
    "print(event2.is_audio_loaded)"
   ],
   "id": "8fe5e426275ac038",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Adding moving events\n",
    "\n",
    "Simple moving `Event`s can be added in the same way as simple static `Event`s."
   ],
   "id": "deef20dc8f767747"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T17:13:23.993569Z",
     "start_time": "2025-11-03T17:13:23.331688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scene.clear_events()\n",
    "moving1 = scene.add_event(event_type=\"moving\", alias=\"my_first_moving_event\")"
   ],
   "id": "484d532959405ff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreateContext: Context created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: initializing context twice. Will destroy old context and create a new one.\n",
      "Placing trajectory...:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Warning: initializing context twice. Will destroy old context and create a new one.\n",
      "\u001B[32m2025-11-03 17:13:23.991\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36maudiblelight.core\u001B[0m:\u001B[36madd_event\u001B[0m:\u001B[36m972\u001B[0m - \u001B[1mEvent added successfully: Moving 'Event' with alias 'my_first_moving_event', audio file '/home/huw-cheston/Documents/python_projects/AudibleLight/tests/test_resources/soundevents/maleSpeech/93856.wav' (unloaded, 0 augmentations), 2 emitter(s).\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreateContext: Context created\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Moving `Event`s expose the same parameters involved when creating a static `Event` (e.g., duration, offset), along with some new ones.\n",
    "\n",
    "In particular, we can control:\n",
    "- the spatial velocity: how fast the event moves, in metres-per-second\n",
    "- the spatial resolution: how many IRs are created per second, in Hz\n",
    "- the trajectory: either `linear`, `circular`, or `random`\n",
    "- the starting position of the event."
   ],
   "id": "a576feaf237079b6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T17:13:25.025068Z",
     "start_time": "2025-11-03T17:13:24.013028Z"
    }
   },
   "cell_type": "code",
   "source": [
    "added2 = scene.add_event(\n",
    "    event_type=\"moving\",\n",
    "    alias=\"my_second_moving_event\",\n",
    "    spatial_velocity=1.,\n",
    "    spatial_resolution=0.5,\n",
    "    shape=\"linear\",\n",
    ")"
   ],
   "id": "2bdf8c2428378698",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Placing trajectory...: 100%|██████████| 1/1 [00:00<00:00,  5.34it/s]\n",
      "Placing trajectory...: 100%|██████████| 1/1 [00:00<00:00,  6.76it/s]\n",
      "Placing trajectory...: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s]\n",
      "\u001B[32m2025-11-03 17:13:24.501\u001B[0m | \u001B[33m\u001B[1mWARNING \u001B[0m | \u001B[36maudiblelight.worldstate\u001B[0m:\u001B[36mdefine_trajectory\u001B[0m:\u001B[36m1966\u001B[0m - \u001B[33m\u001B[1mNumber of points in trajectory (2) is smaller than 2, so it is being clamped to 2 internally. If this is happening frequently, consider increasing `resolution` (currently 0.500).\u001B[0m\n",
      "Placing trajectory...:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Warning: initializing context twice. Will destroy old context and create a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreateContext: Context created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-11-03 17:13:25.021\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36maudiblelight.core\u001B[0m:\u001B[36madd_event\u001B[0m:\u001B[36m972\u001B[0m - \u001B[1mEvent added successfully: Moving 'Event' with alias 'my_second_moving_event', audio file '/home/huw-cheston/Documents/python_projects/AudibleLight/tests/test_resources/soundevents/femaleSpeech/236657.wav' (unloaded, 0 augmentations), 2 emitter(s).\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## A note on class labels\n",
    "\n",
    "By default, `Event` objects will try and define a `class_id` and `class_label` attribute using the 13 classes of the [DCASE 2023 task 3.](https://dcase.community/challenge2024/task-audio-and-audiovisual-sound-event-localization-and-detection-with-source-distance-estimation) `AudibleLight` will attempt to extract these attributes from the filepath of the audio file if they are not passed when creating an `Event`.\n",
    "\n",
    "To show what we mean, let's try adding in a \"femaleSpeech\" audio event (class index 0 for this DCASE challenge)\n"
   ],
   "id": "d9687b203b703a21"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T17:13:25.638495Z",
     "start_time": "2025-11-03T17:13:25.086013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scene.clear_events()\n",
    "female_speech = scene.add_event(\n",
    "    filepath=utils.get_project_root() / \"tests/test_resources/soundevents/femaleSpeech/236385.wav\",\n",
    "    event_type=\"static\"\n",
    ")\n",
    "\n",
    "print(female_speech.class_id)\n",
    "print(female_speech.class_label)"
   ],
   "id": "a672600185e41b8c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: initializing context twice. Will destroy old context and create a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreateContext: Context created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: initializing context twice. Will destroy old context and create a new one.\n",
      "\u001B[32m2025-11-03 17:13:25.636\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36maudiblelight.core\u001B[0m:\u001B[36madd_event\u001B[0m:\u001B[36m972\u001B[0m - \u001B[1mEvent added successfully: Static 'Event' with alias 'event000', audio file '/home/huw-cheston/Documents/python_projects/AudibleLight/tests/test_resources/soundevents/femaleSpeech/236385.wav' (unloaded, 0 augmentations), 1 emitter(s).\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreateContext: Context created\n",
      "0\n",
      "femaleSpeech\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Alternatively, if only one parameter is passed (e.g., just `class_label`), the missing attribute will be inferred from this using these DCASE classes.",
   "id": "8bc814c36df64ba7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T17:13:26.301397Z",
     "start_time": "2025-11-03T17:13:25.644308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scene.clear_events()\n",
    "female_speech = scene.add_event(\n",
    "    filepath=utils.get_project_root() / \"tests/test_resources/soundevents/femaleSpeech/236385.wav\",\n",
    "    event_type=\"static\",\n",
    "    class_id=0\n",
    ")\n",
    "\n",
    "print(female_speech.class_id)\n",
    "print(female_speech.class_label)"
   ],
   "id": "8f4365d01131501",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: initializing context twice. Will destroy old context and create a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreateContext: Context created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: initializing context twice. Will destroy old context and create a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreateContext: Context created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-11-03 17:13:26.298\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36maudiblelight.core\u001B[0m:\u001B[36madd_event\u001B[0m:\u001B[36m972\u001B[0m - \u001B[1mEvent added successfully: Static 'Event' with alias 'event000', audio file '/home/huw-cheston/Documents/python_projects/AudibleLight/tests/test_resources/soundevents/femaleSpeech/236385.wav' (unloaded, 0 augmentations), 1 emitter(s).\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "femaleSpeech\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Of course, these IDs and labels can also be overridden:",
   "id": "731fe1e75ecae4f9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T17:13:26.907055Z",
     "start_time": "2025-11-03T17:13:26.313037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scene.clear_events()\n",
    "custom_event = scene.add_event(\n",
    "    event_type=\"static\",\n",
    "    alias=\"my_custom_event\",\n",
    "    class_id=100,\n",
    "    class_label=\"customClass\",\n",
    "    filepath=utils.get_project_root() / \"tests/test_resources/soundevents/femaleSpeech/236385.wav\",\n",
    ")\n",
    "print(custom_event.class_id)\n",
    "print(custom_event.class_label)"
   ],
   "id": "7456152e445c12ab",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: initializing context twice. Will destroy old context and create a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreateContext: Context created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: initializing context twice. Will destroy old context and create a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreateContext: Context created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-11-03 17:13:26.904\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36maudiblelight.core\u001B[0m:\u001B[36madd_event\u001B[0m:\u001B[36m972\u001B[0m - \u001B[1mEvent added successfully: Static 'Event' with alias 'my_custom_event', audio file '/home/huw-cheston/Documents/python_projects/AudibleLight/tests/test_resources/soundevents/femaleSpeech/236385.wav' (unloaded, 0 augmentations), 1 emitter(s).\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "customClass\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Any metadata generated from the scene (e.g., `generate_dcase2024_metadata`) will adhere to the custom IDs.",
   "id": "de4f7e410edf1976"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### But what if we want to use a different class mapping?\n",
    "\n",
    "It's quite likely that you might want to use a different class mapping than the one defined in DCASE2023, task 3.\n",
    "\n",
    "To solve this, you can pass in a custom mapping when creating a `Scene`. Let's try a custom mapping that maps \"femaleSpeech\" to class index 2, this time:"
   ],
   "id": "fa501b41d0a1eeaf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T17:13:28.799827Z",
     "start_time": "2025-11-03T17:13:26.912603Z"
    }
   },
   "cell_type": "code",
   "source": [
    "custom_scene = Scene(\n",
    "    duration=60,\n",
    "    sample_rate=44100,\n",
    "    backend=\"rlr\",\n",
    "    backend_kwargs=dict(\n",
    "        mesh=utils.get_project_root() / \"tests/test_resources/meshes/Oyens.glb\"\n",
    "    ),\n",
    "    fg_path=utils.get_project_root() / \"tests/test_resources/soundevents\",\n",
    "    class_mapping=dict(\n",
    "        femaleSpeech=2\n",
    "    )\n",
    ")\n",
    "custom_scene.add_microphone(microphone_type=\"ambeovr\")"
   ],
   "id": "ad3bef899497329d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-11-03 17:13:26.954\u001B[0m | \u001B[33m\u001B[1mWARNING \u001B[0m | \u001B[36maudiblelight.worldstate\u001B[0m:\u001B[36mload_mesh_navigation_waypoints\u001B[0m:\u001B[36m1878\u001B[0m - \u001B[33m\u001B[1mCannot find waypoints for mesh Oyens inside default location (/home/huw-cheston/Documents/python_projects/AudibleLight/resources/waypoints/gibson). No navigation waypoints will be loaded.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreateContext: Context created\n",
      "CreateContext: Context created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: initializing context twice. Will destroy old context and create a new one.\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T17:13:29.259781Z",
     "start_time": "2025-11-03T17:13:28.885039Z"
    }
   },
   "cell_type": "code",
   "source": [
    "female_speech_custom = custom_scene.add_event(\n",
    "    filepath=utils.get_project_root() / \"tests/test_resources/soundevents/femaleSpeech/236385.wav\",\n",
    "    event_type=\"static\"\n",
    ")\n",
    "\n",
    "print(female_speech_custom.class_id)\n",
    "print(female_speech_custom.class_label)"
   ],
   "id": "b3e5b95f18badd77",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreateContext: Context created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: initializing context twice. Will destroy old context and create a new one.\n",
      "\u001B[32m2025-11-03 17:13:29.257\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36maudiblelight.core\u001B[0m:\u001B[36madd_event\u001B[0m:\u001B[36m972\u001B[0m - \u001B[1mEvent added successfully: Static 'Event' with alias 'event000', audio file '/home/huw-cheston/Documents/python_projects/AudibleLight/tests/test_resources/soundevents/femaleSpeech/236385.wav' (unloaded, 0 augmentations), 1 emitter(s).\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "femaleSpeech\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "You can also pass in the name of a particular task (e.g., DCASE 2025, task 4) and use the mapping directly, without having to define a dictionary.\n",
    "\n",
    "**Hint**: to see which mappings can be used in this way, check out `audiblelight.class_mappings.py`"
   ],
   "id": "1effaaea406527a0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T17:13:29.519710Z",
     "start_time": "2025-11-03T17:13:29.273706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dcase2025 = Scene(\n",
    "    duration=60,\n",
    "    sample_rate=44100,\n",
    "    backend=\"rlr\",\n",
    "    backend_kwargs=dict(\n",
    "        mesh=utils.get_project_root() / \"tests/test_resources/meshes/Oyens.glb\"\n",
    "    ),\n",
    "    fg_path=utils.get_project_root() / \"tests/test_resources/soundevents\",\n",
    "    class_mapping=\"dcase2025task4\"\n",
    ")"
   ],
   "id": "b59a65fd651b29f3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-11-03 17:13:29.315\u001B[0m | \u001B[33m\u001B[1mWARNING \u001B[0m | \u001B[36maudiblelight.worldstate\u001B[0m:\u001B[36mload_mesh_navigation_waypoints\u001B[0m:\u001B[36m1878\u001B[0m - \u001B[33m\u001B[1mCannot find waypoints for mesh Oyens inside default location (/home/huw-cheston/Documents/python_projects/AudibleLight/resources/waypoints/gibson). No navigation waypoints will be loaded.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreateContext: Context created\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can also use `Scene.get_class_mapping` to check the current class mapping:",
   "id": "213a77e3bded7dd2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T17:13:29.537608Z",
     "start_time": "2025-11-03T17:13:29.529945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compare with https://dcase.community/challenge2025/task-spatial-semantic-segmentation-of-sound-scenes#audio-dataset\n",
    "dcase2025.get_class_mapping()"
   ],
   "id": "cfb5c7faa5fa5d87",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AlarmClock': 0,\n",
       " 'BicycleBell': 1,\n",
       " 'Blender': 2,\n",
       " 'Buzzer': 3,\n",
       " 'Clapping': 4,\n",
       " 'Cough': 5,\n",
       " 'CupboardOpenClose': 6,\n",
       " 'Dishes': 7,\n",
       " 'Doorbell': 8,\n",
       " 'FootSteps': 9,\n",
       " 'HairDryer': 10,\n",
       " 'MechanicalFans': 11,\n",
       " 'MusicalKeyboard': 12,\n",
       " 'Percussion': 13,\n",
       " 'Pour': 14,\n",
       " 'Speech': 15,\n",
       " 'Typing': 16,\n",
       " 'VacuumCleaner': 17}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
